# ğŸ§  Deploying ResNetâ€‘50 (ImageNetâ€‘1k) to Huggingâ€¯Faceâ€¯Spaces â€”â€¯Cookbookâ€¯Guide

This document is a **complete, beginnerâ€‘friendly cookbook** to take you from a *training checkpoint* to a working **Huggingâ€¯Faceâ€¯Space** that runs entirely on **CPU** using **Gradio**.  
Itâ€™s written from realâ€‘world deployment experience with both **local RTXâ€¯4060â€¯Ti** and **AWSâ€¯A10Gâ€¯(g5.xlarge)** ImageNetâ€¯trainings.

---

## 1ï¸âƒ£â€¯Overview

We trained two ResNetâ€‘50 ImageNetâ€‘1k models (localâ€¯+â€¯AWS) and then deployed them for public interactive inference.  
This guide explains the **endâ€‘toâ€‘end process** so anyone can reproduce the same deployment for any PyTorch model.

---

## 2ï¸âƒ£â€¯Prerequisites

Before you start:
- You already have a **saved training checkpoint** â€” for example:
  ```bash
  checkpoints/r50_imagenet1k_onecycle_amp_bs64_ep150/best.pth
  checkpoints/imagenet1kfull_g5x_1gpu_dali_nvme_lr0p125_bs256_e150_work6/best_acc_epoch193.pth
  ```
- The checkpoint dict should contain your model state under `"model"` key (typical ERA / DDP style).  
- You know the training mean / std values (these will be stored in `meta.json`).

Optional but recommended:
- A Huggingâ€¯Face account (`https://huggingface.co/join`)
- Installed CLI:
  ```bash
  pip install huggingface_hub
  huggingface-cli login
  ```

---

## 3ï¸âƒ£â€¯Stepâ€‘byâ€‘Stepâ€¯Deploymentâ€¯Recipe

### ğŸ§©â€¯Stepâ€¯1â€¯â€“â€¯Convertâ€¯yourâ€¯trainingâ€¯checkpointâ€¯toâ€¯CPUâ€¯weights

Weâ€™ll remove optimizer/scheduler/AMP states and save a clean fp32â€¯state_dict.

```python
# convert_to_cpu.py
import json, torch
from torchvision.models import resnet50

CKPT_PATH = r"/path/to/your/best_or_last_checkpoint.pth"
OUT_FP32  = "model_cpu_fp32.pth"
OUT_META  = "meta.json"

def strip_prefixes(sd: dict) -> dict:
    out = {}
    for k, v in sd.items():
        if k.startswith("module."):
            out[k[7:]] = v
        elif k.startswith("model."):
            out[k[6:]] = v
        else:
            out[k] = v
    return out

def main():
    obj = torch.load(CKPT_PATH, map_location="cpu")
    sd  = strip_prefixes(obj["model"])
    for k, v in list(sd.items()):
        if torch.is_tensor(v):
            sd[k] = v.float().cpu()

    m = resnet50(weights=None)
    m.load_state_dict(sd, strict=False)

    torch.save(m.state_dict(), OUT_FP32)
    mean = obj.get("mean", [0.485, 0.456, 0.406])
    std  = obj.get("std",  [0.229, 0.224, 0.225])
    json.dump({"mean": [float(x) for x in mean],
               "std":  [float(x) for x in std],
               "image_size": 224}, open(OUT_META, "w"))
    print("âœ…â€¯Saved:", OUT_FP32, OUT_META)

if __name__ == "__main__":
    main()
```

Youâ€™ll now have:
```
model_cpu_fp32.pth
meta.json
```

---

### ğŸ§®â€¯Stepâ€¯2â€¯â€“â€¯Verifyâ€¯locally

```bash
python -m venv .venv && . .venv/Scripts/activate
pip install torch torchvision pillow requests numpy gradio
python app.py
```
Open http://127.0.0.1:7860 â€” test image upload + URL prediction.

If predictions look wrong for every image â†’ check console:  
it should print `[info] using meta normalization: mean=[...], std=[...]`.

---

### ğŸ—‚ï¸â€¯Stepâ€¯3â€¯â€“â€¯Uploadâ€¯weightsâ€¯toâ€¯Huggingâ€¯Faceâ€¯Modelâ€¯Hub

Create a new model repo:
```bash
huggingface-cli repo create my-resnet50-cpu --type model
```
Push your two files:
```bash
git clone https://huggingface.co/<user>/my-resnet50-cpu
cd my-resnet50-cpu
cp ../model_cpu_fp32.pth ../meta.json .
git add . && git commit -m "Add CPU model + meta" && git push
```

---

### âš™ï¸â€¯Stepâ€¯4â€¯â€“â€¯Buildâ€¯yourâ€¯Space

Create a new **Space** at <https://huggingface.co/new-space>  
Set **SDKâ€¯=â€¯Gradio**, and **Hardwareâ€¯=â€¯CPUâ€¯Basic**.

Then upload these files:

| File | Purpose |
|------|----------|
| `app.py` | Gradioâ€¯UI definition |
| `inference.py` | Modelâ€¯loaderâ€¯+â€¯predictor |
| `requirements.txt` | Pinnedâ€¯packages |
| `runtime.txt` | Pythonâ€¯version (e.g.,â€¯`pythonâ€‘3.10`) |
| `utils/imagenet_class_index.json` | Humanâ€¯labels (optional) |
| `README.md` | Spaceâ€¯frontâ€‘matterâ€¯metadata |

**Important fields inside `inference.py`:**
```python
HF_MODEL_REPO = "<user>/my-resnet50-cpu"
HF_MODEL_FILE = "model_cpu_fp32.pth"
```
Saveâ€¯â†’â€¯Commitâ€¯â†’â€¯â€œRestartâ€¯Spaceâ€.  
Withinâ€¯~2â€¯minutesâ€¯yourâ€¯appâ€¯buildsâ€¯andâ€¯showsâ€¯`Running`.

---

## 4ï¸âƒ£â€¯Testâ€¯Yourâ€¯Space

Once it runs, open:
```
https://huggingface.co/spaces/<user>/<space-name>
```
Upload an image or paste an imageâ€¯URL â†’ youâ€™ll see Topâ€‘Kâ€¯predictionsâ€¯withâ€¯confidence.

> ğŸ’¡â€¯Hint:â€¯You can check build logs via *Settingsâ€¯â†’â€¯Logs* if itâ€™s stuckâ€¯onâ€¯â€œBuildingâ€â€¯orâ€¯â€œErrorâ€¯startingâ€¯serverâ€.

---

## 5ï¸âƒ£â€¯Howâ€¯Othersâ€¯Canâ€¯Accessâ€¯Yourâ€¯Work

### Cloneâ€¯theâ€¯Spaceâ€¯(codeâ€¯+â€¯UI)
```bash
git lfs install
git clone https://huggingface.co/spaces/<user>/<space-name>
```

### Downloadâ€¯modelâ€¯snapshotâ€¯(weightsâ€¯+â€¯meta)
```bash
pip install huggingface_hub
python - <<'PY'
from huggingface_hub import snapshot_download
snapshot_download(repo_id="<user>/my-resnet50-cpu", local_dir="./model_download")
PY
```

### Orâ€¯downloadâ€¯aâ€¯singleâ€¯fileâ€¯(rawâ€¯URL)
Inâ€¯theâ€¯Hubâ€¯UIâ€¯â†’â€¯**Files**â€¯â†’â€¯clickâ€¯onâ€¯`model_cpu_fp32.pth`â€¯â†’â€¯**Raw**â€¯â†’â€¯copyâ€¯URL.  
Then:
```bash
curl -L -o model_cpu_fp32.pth "<raw-url>"
```

---

## 6ï¸âƒ£â€¯Commonâ€¯Issuesâ€¯&â€¯Fixes

| Problem | Causeâ€¯/â€¯Fix |
|----------|-------------|
| ğŸ”â€¯Packageâ€¯conflictsâ€¯(`gradio_client`) | Pinâ€¯Gradioâ€¯e.g.,â€¯`gradio==4.44.1`;â€¯removeâ€¯manualâ€¯`gradio_client`â€¯pin. |
| âš ï¸â€¯Everythingâ€¯predictsâ€¯sameâ€¯class | Missingâ€¯meta.jsonâ€¯â†’â€¯wrongâ€¯normalization.â€¯Ensureâ€¯youâ€¯seeâ€¯consoleâ€¯logâ€¯forâ€¯mean/std. |
| âŒâ€¯Checkpointâ€¯failsâ€¯toâ€¯load | Headâ€¯mismatchâ€¯â†’â€¯checkâ€¯thatâ€¯`fc.weight`â€¯shapeâ€¯=â€¯[1000,â€¯2048]. |
| â³â€¯Spaceâ€¯stuckâ€¯onâ€¯Building | Restartâ€¯Spaceâ€¯/â€¯Clearâ€¯cacheâ€¯/â€¯Rebuildâ€¯Factoryâ€¯(underâ€¯Settings). |
| ğŸ’¥â€¯Internalâ€¯Serverâ€¯Error | Keepâ€¯Gradioâ€¯â‰¤â€¯4.44â€¯andâ€¯useâ€¯simpleâ€¯componentsâ€¯(noâ€¯BarPlotâ€¯schemaâ€¯bugs). |

---

## 7ï¸âƒ£â€¯Securityâ€¯Tips

âœ…â€¯Safeâ€¯toâ€¯publish:
```
app.py
inference.py
requirements.txt
runtime.txt
utils/*
meta.json
README.md
```
ğŸš«â€¯Doâ€¯NOTâ€¯commit:
```
.env
.token*
.netrc
*.pt
*.pth
*.ckpt
__pycache__/
```

If you ever need secrets, store them under **Spaceâ€¯â†’â€¯Settingsâ€¯â†’â€¯Repositoryâ€¯Secrets** and access viaâ€¯`os.environ`.

---

## 8ï¸âƒ£â€¯Liveâ€¯Demoâ€¯Placeholders

| Modelâ€¯Type | Description | Spaceâ€¯Link |
|-------------|--------------|------------|
| ğŸ–¥ï¸â€¯Localâ€¯CPU | Trainedâ€¯onâ€¯RTXâ€¯4060â€¯Tiâ€¯(OneCycleLRâ€¯+â€¯AMP) | [ğŸ”—â€¯Liveâ€¯Demo](https://huggingface.co/spaces/<user>/<local-space>) |
| â˜ï¸â€¯AWSâ€¯Model | Trainedâ€¯onâ€¯A10Gâ€¯(g5.xlarge)â€¯withâ€¯DALIâ€¯pipeline | [ğŸ”—â€¯Liveâ€¯Demo](https://huggingface.co/spaces/<user>/<aws-space>) |

---

## 9ï¸âƒ£â€¯Keyâ€¯Takeaways

- Converting to a **clean CPUâ€¯fp32** checkpoint is critical for portable deployment.  
- `meta.json` ensures identical preprocessingâ€¯(mean/std/imageâ€¯size).  
- Pinâ€¯versionsâ€¯toâ€¯avoidâ€¯resolverâ€¯conflicts.  
- You can replicate this pipeline for any PyTorchâ€¯model â€”â€¯justâ€¯swapâ€¯`resnet50()`â€¯withâ€¯yourâ€¯ownâ€¯architecture.

---

> ğŸ§¾â€¯**Note:**â€¯Thisâ€¯READMEâ€¯isâ€¯theâ€¯completeâ€¯deploymentâ€¯cookbook.  
> Pairâ€¯itâ€¯withâ€¯yourâ€¯mainâ€¯projectâ€¯READMEâ€¯sectionâ€¯â€œModelâ€¯Deploymentâ€¯andâ€¯Inferencingâ€â€¯forâ€¯aâ€¯perfectâ€¯submission.
